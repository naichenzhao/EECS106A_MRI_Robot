<!DOCTYPE html>
<html>

<head>
    <!-- Standard stuff -->
    <meta charset="utf-8" \>
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />

    <title>MRI Robot</title>

    <!-- Metadata -->
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="author" content="" \>
    <meta name="description" content="UC Berkeley EECS C106A Fall 2023 Project Report" \>

    <!-- Style info -->
    <link rel="stylesheet" href="ee106a_project_assets/styles/styles.css" />
    <script src='https://cdn.plot.ly/plotly-2.27.0.min.js'></script>
	<script src='https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.17/d3.min.js'></script>
</head>

<body>
    <div class="main">
        <h1> EE106A Fall 2023 Final Project</h1>
        <h2> Group 35 - MRI Robot </h2>
        <p> David Guo, Nai Chen Zhao, Wesley Jiang, Cedric Murphy, Charles Paxson </p>
        <div class="section" id="introduction">
            <h2> Introduction </h2>
            <p> Transcranial Magnetic Stimulation (TMS) is a procedure that uses powerful magnetic fields emitted from a handheld coil to stimulate certain areas of the brain.  It has been found to have positive effects on patients with depression and obsessive-compulsive disorders.</p>
            <p> However, the exact biology of TMS is not very well understood.  Our robot is intended to help study TMS and its effects on the brain by allowing it to be conducted repeatably within an MRI machine, so imagery can be taken immediately following the stimulation. </p>
            <p> Since this robot will be able to function around an MRI machine, it could be used for other research and procedures relating to the brain. </p>
        </div>
        <div class="section" id="design">
            <h2> Design </h2>
            <p> Our robot must be able to move a TMS coil into light contact with a human head, within an MRI machine.</p>
            <p> In doing so, it must be reliable, safe, and easy for the therapist conducting TMS to control.</p>
            <p> Since this robot will work within an MRI machine, it cannot have any ferromagnetic materials.  However, this project is simply a prototype to test the overall architecture, so there are several ferromagnetic components</p>
            <div class="subsection" id="hardware-design">
                <h3> Hardware </h3>
                <h4> Design Overview </h4>
                <p> We designed a 6-axis robot, composed of two main assemblies: a 3 axis Cartesian gantry, and a 3 axis rotating end effector.</p>
                <img src="ee106a_project_assets/images/design/robot_cad.png" alt="Robot CAD image" class="picture center">
                <p> The rotating end effector then has two parts: a rotation joint and a two-axis differential wrist joint.  We use this differential joint instead of discreetly actuating the pitch and yaw axes to reduce the number of wires that need to move around a joint, and to make the end effector more compact. </p>
                <img src="ee106a_project_assets/images/design/differential_joint.png" alt="Differential joint image" class="picture center">
                <p> Each of the prismatic joints is belt-driven directly by the stepper motors. </p>
                <p> The rotating joint (roll) connecting the gantry to the wrist has a worm drive. </p>
                <p> The wrist joint has 2 axes, each driven by a pancake stepper motor with a 15:1 3D printed cycloidal drive.  These drives have custom bearings with nylon balls running in 3D printed races. </p>
                <img src="ee106a_project_assets/images/design/cycloidal_drive_cad.png" alt="Cycloidal drive image" class="picture center">
                <p> These drive timing belts that move the two sides of a bevel gear differential, upon which is mounted our force/torque sensor and end effector. </p>
                <h4> Design Choices and Trade-offs </h4>
                <p> When we began this project, the Cartesian gantry had already been bought, and unfortunately its range of motion was rather lacking.  We had to offset the wrist joint from the rotation joint to give us a usable reachable workspace that would let us reach either side of an adult human's head.  We also had to cut down the workspace, so the arm can only either reach the front half of a person's head, and the back half, with the patient simply be turned over on the tray to reach the other side. </p>
                <p> Additionally, the gantry we ultimately received lacked a couple of key components, most importantly the rotation joint.  It was shipped later, but it did not have any kind of motor mount, so we just designed our own. </p>
                <p> Finally, we got a prototype of the wrist arm made of acetal, and we noticed that with the NEMA 23 motors we originally planned to use, that bending was a concern.  To solve this, we remade the wrist arm with acrylic, and designed 3D printed cycloidal drives that would allow us to use 50mm pancake stepper motors instead that were much lighter. </p>
            </div>
            <div class="subsection" id="electrical-design">
                <h3> Electrical </h3>
                <p> Since we are just working on a prototype, we decided to drive our robot with stepper motors, since they are precise and easy to use.</p>
                <p> To make the wiring between the encoders, motor drivers, and microcontroller simpler, we designed a custom PCB with a socket to directly plug in the STM32 Nucleo microcontroller.  It manages power conversions from 24V to 5V and 3.3V.  It greatly simplifies wiring and minimizes harnessing issues.</p>
                <img src="ee106a_project_assets/images/design/pcb_cad.png" alt="PCB image" class="picture center">
                <p> It has five main features for each motor: </p>
                <ul>
                    <li> A STEP/DIR/ENA interface to each stepper driver </li>
                    <li> A quadrature encoder interface </li>
                    <li> A limit switch interface </li>
                    <li> A ENA switch to toggle individual motors </li>
                    <li> A XT-60 connector for power to stepper drivers. (this connector has a 60A rating and we will draw at most 1A at 24V) </li>
                </ul>
                <p> The X, Y, and all three revolute axes are driven by TB6600 stepper drivers, which were perfect for our application since they can supply high current and were quite cheap.</p>
            </div>
            <div class="subsection" id="software-design"> 
                <h3> Software </h3>
                <img src="ee106a_project_assets/images/software-architecture.png" alt="Software architecture flowchart" class="picture center">
                <h4> Controller </h4>
                <p> Runs ROS Noetic on a Ubuntu 20.04 VM. There are five main nodes: </p>
                <ul>
                    <li> Head GUI </li>
                    <li> OptiTrack Receiver </li>
                    <li> Path planner </li>
                    <li> STM32 Interface </li>
                    <li> Force/Torque Receiver </li>
                </ul>
                <p> The Head GUI will publish a point cloud, and a selected point.  This data is passed through a TF transform obtained from the OptiTrack node, where the now-transformed point is sent to the path planner, and the point cloud is displayed on RViz. </p>

                <p> The path planner is the most important node.  It takes in sensor data, the desired input, calculates a path, then uses MoveIt to determine the required joint angles.  Finally, it displays that plan on RViz for the user to confirm the trajectory, upon which it will be sent to the low-level controller through the STM32 interface node. </p>
                
                <h4> Low-level Controller </h4>
                <p> The low-level controller runs entirely on the STM32.  It takes in UART commands over USB to drive the motors. </p>
                <p> For the three prismatic joints of the Cartesian gantry, it runs a PID controller for each motor since those joints have functional encoders (It isn't strictly necessary on the Z axis since it has a lead screw instead of easy to back-drive belts that are on the X and Y axes) </p>
                <p> For the three revolute joints, it just runs the motors in open-loop since the gear reductions on those joints are relatively high so backdriving is unlikely. </p>
            </div>
        </div>
        <div class="section" id="implementation">
            <h2> Implementation </h2>
            <div class="subsection" id="hardware-implementation">
                <h3> Hardware </h3>
                <p> The manufacturing and assembly processes were fairly straightforward on the mechanical side. </p>
                <div style="text-align:center">
                    <span class="dot" onclick="currentSlide(1)"></span>
                    <span class="dot" onclick="currentSlide(2)"></span>
                    <span class="dot" onclick="currentSlide(3)"></span>
                    <span class="dot" onclick="currentSlide(4)"></span>
                    <span class="dot" onclick="currentSlide(5)"></span>
                    <span class="dot" onclick="currentSlide(6)"></span>
                    <span class="dot" onclick="currentSlide(7)"></span>
                </div>
                <br>
                <div class="carousel">
                    <div class="carousel-card">
                        <img src="ee106a_project_assets/images/mechanical_implementation/trimetric_front.jpg" alt="Gantry assembly" class="carousel-image picture">
                        <div class="carousel-caption"> Front Trimetric View </div>
                    </div>
                    <div class="carousel-card">
                        <img src="ee106a_project_assets/images/mechanical_implementation/differential_joint.jpg" alt="Differential joint" class="carousel-image picture">
                        <div class="carousel-caption"> Differential Joint with Limit Switches </div>
                    </div>
                    <div class="carousel-card">
                        <img src="ee106a_project_assets/images/mechanical_implementation/cycloidal_drive.jpg" alt="Cycloidal drive" class="carousel-image picture">
                        <div class="carousel-caption"> Mounted Cycloidal Drive </div>
                    </div>
                    <div class="carousel-card">
                        <img src="ee106a_project_assets/images/mechanical_implementation/rotation_joint.jpg" alt="Rotation Joint" class="carousel-image picture">
                        <div class="carousel-caption"> Rotation Joint with Motor Mount and Limit Switch </div>
                    </div>
                    <div class="carousel-card">
                        <img src="ee106a_project_assets/images/mechanical_implementation/arm_offset.jpg" alt="Wrist offset mount" class="carousel-image picture">
                        <div class="carousel-caption"> Wrist Arm Offset Mount </div>
                    </div>
                    <div class="carousel-card">
                        <img src="ee106a_project_assets/images/mechanical_implementation/wesley_mount.jpg" alt="Mannequin bracket" class="carousel-image picture">
                        <div class="carousel-caption"> "Wesley" mount with OptiTrack markers (our mannequin head is named Wesley because <i>true</i> Wesley wasn't there when we named it) </div>
                    </div>
                    <div class="carousel-card">
                        <img src="ee106a_project_assets/images/mechanical_implementation/trimetric_back.jpg" alt="Gantry Assembly" class="carousel-image picture">
                        <div class="carousel-caption"> Back Trimetric View </div>
                    </div>
                    <a class="prev-button" onclick="plusSlides(-1)">&#10094;</a>
                    <a class="next-button" onclick="plusSlides(1)">&#10095;</a>
                </div>
            </div>
            <div class="subsection" id="electrical-implementation">
                <h3> Electrical </h3>
                <p> This is the PCB mounted and wired to all the stepper drivers.  You may notice that there are only 5 motor drivers, despite us having 6 motors.  This is because the Z axis motor is closed-loop and has a built-in stepper driver.</p>
                <img src="ee106a_project_assets/images/electrical_implementation/board_2.jpg" alt="PCB and motor drivers" class="picture center">
                <p> This motor had an issue with the 3.3V logic on the STM32 for only the DIR pin, so we had to create a pull-up for the signal to 5V, which was done with a random NAND gate chip we found and a mini breadboard. </p>
                <br>
                <p> We also had some issues with the encoder wires, this time due to software issues with the STM32 on certain pins.  So, we rewired a few of the encoder pins. </p>
                <img src="ee106a_project_assets/images/electrical_implementation/rerouting.jpg" alt="Rerouted traces" class="picture center">
            </div>
            <div class="subsection" id="software-implementation">
                <h3> Software </h3>
                <h4> Head GUI </h4>
                <img src="ee106a_project_assets/images/head_gui_demo.gif" alt="Head GUI demo" class="picture center" id="demo-animation">
                <p> A python GUI allows a user to select head zones.  This ran independently of RVIZ.  Not all points on the head are selectable since the back half is unreachable.  An even point density cloud was achieved with voxel down-sampling.  The GUI transforms the head normal vectors and points to the world frame and publishes them. </p>
                <div id="head_gui_plot"></div>
                <i class="caption"> Point cloud data shown with Plotly.js instead of Matplotlib, which we use with ROS. </i>
                <h4> Path Planner </h4>
                <p>The path planner waits for a target point and normal vector from the Head GUI node, and when it gets a target, it transforms the point and normal vector to the robot frame using the OptiTrack data.
                </p>
                <p>It takes this target position and calculates a corresponding position on a "safety sphere" that is larger than the head, and sends both of these positions to MoveIt for inverse kinematics.</p>
                <img src="ee106a_project_assets/images/moveit.png" alt="Head and safety sphere" class="picture center" style="border-radius: 5px;">
                <i class="caption"> Robot shown about the head point cloud with the safety sphere in MoveIt</i>
                <p>With the returned joint positions, it sends commands through the STM32 Interface to the robot to first move to a home position on the correct side of the head, before plunging into the position on the "safety sphere".</p>
                <p>At this point, it switches to "critical" mode, where the robot will move much slower, and plunge towards the head while taking continuously checking the force from the F/T sensor.  When it reaches a threshold, the robot stops and backs up slightly.  At this point, TMS could be conducted on the patient.</p>
                <p>Finally, the planner executes similar steps in reverse to safely retract from the head and wait for the next target point.</p>
                <h4> STM32 Firmware </h4>
                <p>The firmware receives serial commands containing the motor positions each joint should move to. </p>
                <p> The motors are controlled using the AccelStepper library, which allows us to send either a position or velocity command to each motor.  This made implementing both open-loop control and closed-loop PID control much easier. </p>
                <p> There are then two speed states: "standard" and "critical".  Standard mode is used to move and position far away from the head, and while approaching the head we use the critical mode to move much slower and listen for a stop command from serial. </p>
                <h4> STM32 Interface </h4>
                <p> The STM32 interface node takes messages from the data from the path planner and sends it over serial to the STM32 for execution.  It also takes the encoder readings from the STM32 and sends them to RViz to allow the robot model to update its position in real-time. </p>
                <h4> OptiTrack </h4>
                <p> We reused the OptiTrack setup that our lab already had, but we had to redo the calibration and learn the ins and outs of the system.  It consists of 8 IR cameras with IR emitters that are connected over USB to a desktop PC running an application called <a href="https://optitrack.com/software/motive/">Motive</a>. </p>
                <img src="ee106a_project_assets/images/optitrack_cameras.jpg" alt="Mounted OptiTrack cameras" class="picture center">
                <p> Motive filters the images from these cameras to isolate the IR reflective tracking points, and uses two-view geometry to locate them in 3D space.  A set of at least 3 points can be combined into a "trackable", which allows it to calculate a 3D pose of the object.</p>
                <div class="side-by-side">
                    <img src="ee106a_project_assets/images/motive_trackables.jpg" alt="Motive tracking objects" class="picture side-by-side-images">
                    <img src="ee106a_project_assets/images/rviz_trackables.jpg" alt="RViz tracking objects" class="picture side-by-side-images">
                </div>
                <p> Our Motive license is from 2011, and it would cost at least $1000 to update.  We had a lot of issues calibrating the cameras, which could possibly have been solved with a newer version of the software that continuously refines the calibration as the system is used.  Even with the issues, though, we were able to get decent tracking data sent to ROS. </p>
                <p> However, even if we updated the software, Motive is only compatible with Windows.  This meant that, to be compatible with all our ROS software, we had to use a separate Ubuntu computer for ROS and a Windows computer for Motive, using the Virtual Reality Peripheral Network (VRPN) interface to transfer the tracking data over a local network. </p>
                <img src="ee106a_project_assets/images/optitrack_system.png" alt="OptiTrack block diagram" class="picture center">
                <i class="caption">The blue box on the right represents a USB hub, connecting the cameras to the Motive PC, and then uses VRPN to send data through a LAN to ROS.</i>
            </div>
        </div>
        <div class="section", id="results"> 
            <h2> Results and Conclusion </h2>
            <p> Ultimately, our project functioned fairly well.  It was able to target a point on our mannequin head and then touch it at that point. </p>
            <iframe class="center" style="aspect-ratio: 16/9;" src="https://www.youtube.com/embed/CVe0IXFgKIg" title="EECS C106A MRI Robot Demonstration Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
            <p> However, it still has a long way to go.  We had several issues in the current solution, and have more features we want to implement for this project. </p>
            <div style="display: flex; align-items: baseline">
                <div style="width: 50%">
                    <p style="text-align: center;"> <b>Issues</b> </p>
                    <ul>
                        <li> Encoders on the revolute joints didn't work, which we believe was due to electromagnetic interference from the motors. If this is a problem now, it will be even worse in the multi-Tesla magnetic field of the MRI, so we have to get new encoders. </li>
                        <li> The OptiTrack software license we have is from 2011, so it has a lot of quirks and was kind of unreliable.  Also, the calibration of the system takes forever and often fails to be perfect.  We may end up reconfiguring the cameras to target the mannequin head more directly, or find another tracking system to localize the head. </li>
                        <li> MoveIt's inverse kinematics solver was really finicky, which we believe is partially due to our quaternion implementation, and partly due to the solver not being optimized for prismatic joints.  So, we plan to create a custom IK solver, since with our current robot architecture, it is rather simple to derive. </li>
                    </ul>
                </div>
                <div style="width: 50%">
                    <p style="text-align: center;"> <b>Future plans</b> </p>
                    <ul>
                        <li> Integrate non-ferromagnetic ultrasonic motors </li>
                        <li> Finish iterating on the Series Elastic Actuator (SEA) design and integrate it into the robot to allow for more force sensing </li>
                        <li> Get a new, non-ferromagnetic and more reliable force/torque sensor (we've been having connectivity issues) </li>
                        <li> Rebuild the gantry without any ferromagnetic materials, buy a new, larger one, or switch to an articulated arm architecture </li>
                        <li> Use the torque reading from the sensor to automatically get closer to truly tangent to the head </li>
                        <li> Create a UI to allow a therapist to manually dial in the position of the TMS coil </li>
                    </ul>
                </div>
            </div>
        </div>
        <div class="section", id="team"> 
            <h2> Team </h2>
            <div class="team-container">
                <div class="team-member">
                    <img src="ee106a_project_assets/images/team/david_guo.jpg" alt="David Guo" class="team-picture">
                    <div class="team-text">
                        <div class="team-name"> <b>David Guo</b> - MechE </div>
                        <div class="team-desc"> MechE major and EECS minor. Experience in mechanical engineering design for collegiate Formula SAE competition series. </div>
                    </div>
                </div>
                <div class="team-member">
                    <img src="ee106a_project_assets/images/team/naichen_zhao.jpg" alt="Naichen Zhao" class="team-picture">
                    <div class="team-text">
                        <div class="team-name"> <b>Naichen Zhao</b> - EECS/MechE </div>
                        <div class="team-desc"> EECS and Mechanical Engineering Major. I am very good at breaking robots and burning motor controllers </div>
                    </div>
                </div>
                <div class="team-member">
                    <img src="ee106a_project_assets/images/team/wesley_jiang.jpg" alt="Wesley Jiang" class="team-picture">
                    <div class="team-text">
                        <div class="team-name"> <b>Wesley Jiang</b> - EECS </div>
                        <div class="team-desc"> Hi! This was my first time ever attempting anything in robotics. In the past, I've taken analog/digital/software courses here at Cal. On the side, I like to try to fix up old broken tech. </div>
                    </div>
                </div>
                <div class="team-member">
                    <img src="ee106a_project_assets/images/team/cedric_murphy.jpeg" alt="Cedric Murphy" class="team-picture">
                    <div class="team-text">
                        <div class="team-name"> <b>Cedric Murphy</b> - EECS </div>
                        <div class="team-desc"> EECS major, PCB, Digital/Analog Design, Ex-Lockheed Martin Intern </div>
                    </div>
                </div>
                <div class="team-member">
                    <img src="ee106a_project_assets/images/team/charles_paxson_photo.jpg" alt="Charles Paxson" class="team-picture">
                    <div class="team-text">
                        <div class="team-name"> <b>Charles Paxson</b> - MechE </div>
                        <div class="team-desc"> Mechanical Engineering major and EECS minor, with six years of experience in FIRST competitive robotics.  Well-versed with CAD, 3D printing, and basic electronics.</div>
                    </div>
                </div>
            </div>
        </div>
        <div class="section", id="additional-materials"> 
            <h2> Additional Materials </h2>
            <p> All of our data is available on our <a href="https://github.com/naichenzhao/EECS106A_Project">GitHub repository</a>! </p>
            <p><code>ros_workspaces</code> - ROS workspace containing all our nodes</p>
            <p><code>EECS106a_STM32</code> - STM32 firmware</p>
            <p><code>SLD_exporter</code> - CAD files</p>
            <p><code>master_node</code> - PCB design files</p>
            <p><code>website</code> - Website assets</p>
        </div>
        <div class="subsection", id="credits">
            <h3> Credits/Thanks</h3>
            <h4>Project</h4>
            <ul>
                <li>Everyone in the Biomimetics Millisystems Laboratory.  In particular:</li>
                    <ul>
                        <li> Binghan He </li>
                        <li> Sareum Kim </li>
                        <li> Martin Zeng </li>
                        <li> Daniel Dapula </li>
                        <li> Ronald Fearing </li>
                    </ul>
                <li>EECS C106A Staff</li>
                <li> TAMS Group - created a <a href="https://github.com/TAMS-Group/tams_wireless_ft">ROS node to interface with the ATI-IA Wireless F/T system</a></li>
                <li> ROS Packages </li>
                    <ul>
                        <li> <a href="https://moveit.ros.org/">MoveIt</a> </li>
                        <li> <a href="https://wiki.ros.org/rviz">RViz</a> </li>
                        <li> <a href="https://wiki.ros.org/vrpn_client_ros">vrpn_client_ros</a> </li>
                    </ul>
            </ul>
            <h4>Website</h4>
            <ul>
                <li> Image slideshow code - <a href="https://www.w3schools.com/howto/howto_js_slideshow.asp">W3Schools</a></li>
                <li> <a href="https://plotly.com/javascript/">Plotly Javascript library</a> </li>
            </ul>
        </div>
    </div>
    <div class="sidebar">
        <ul id="toc">
            <li><a class="toc-section" href="#introduction">Introduction</a></li>
            <li><a class="toc-section" href="#design">Design</a></li>
                <li><a class="toc-subsection" href="#hardware-design">Hardware</a></li>
                <li><a class="toc-subsection" href="#electrical-design">Electrical</a></li>
                <li><a class="toc-subsection" href="#software-design">Software</a></li>
            <li><a class="toc-section" href="#implementation">Implementation</a></li>
                <li><a class="toc-subsection" href="#hardware-implementation">Hardware</a></li>
                <li><a class="toc-subsection" href="#electrical-implementation">Electrical</a></li>
                <li><a class="toc-subsection" href="#software-implementation">Software</a></li>
            <li><a class="toc-section" href="#results">Results & Conclusion</a></li>
            <li><a class="toc-section" href="#team">Team</a></li>
            <li><a class="toc-section" href="#additional-materials">Additional Materials</a></li>
        </ul>
    </div>
</body>
<script src="ee106a_project_assets/scripts/scripts.js"></script>
</html>